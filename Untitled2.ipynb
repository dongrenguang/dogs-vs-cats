{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications import Xception, xception\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Dense, Input, Lambda\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [00:56<00:00, 441.43it/s]\n",
      " 12%|█▏        | 910/7393 [00:03<00:26, 240.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Abyssinian_102.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1038/7393 [00:04<00:26, 241.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Abyssinian_100.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1447/7393 [00:05<00:24, 242.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Egyptian_Mau_139.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 2747/7393 [00:11<00:19, 241.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Egyptian_Mau_145.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4236/7393 [00:17<00:12, 243.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Egyptian_Mau_177.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 5505/7393 [00:22<00:07, 242.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Abyssinian_101.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 5632/7393 [00:23<00:07, 242.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Egyptian_Mau_191.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 5786/7393 [00:23<00:06, 242.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Abyssinian_34.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 7279/7393 [00:30<00:00, 242.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read extra train image failed: ../dogs-vs-cats-dataset/images-Oxford-IIIT/Egyptian_Mau_167.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7393/7393 [00:30<00:00, 242.00it/s]\n",
      "100%|██████████| 12500/12500 [00:28<00:00, 441.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 32384\n",
      "Label size: 32384\n",
      "Testing data size: 12500\n"
     ]
    }
   ],
   "source": [
    "data_path_train = '../dogs-vs-cats-dataset/train'\n",
    "data_path_train_extra = '../dogs-vs-cats-dataset/images-Oxford-IIIT'\n",
    "data_path_test = '../dogs-vs-cats-dataset/test'\n",
    "image_names_train = os.listdir(data_path_train)\n",
    "image_names_train_extra = os.listdir(data_path_train_extra)\n",
    "image_names_test = os.listdir(data_path_test)\n",
    "input_shape = (299, 299, 3)\n",
    "labels = []\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "\n",
    "# 处理标准的训练数据\n",
    "for i in tqdm(range(len(image_names_train))):\n",
    "    image_name = image_names_train[i]\n",
    "    image_path = os.path.join(data_path_train, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print('Read train image failed:', image_path)\n",
    "        continue\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    trains.append(image[:, :, ::-1])\n",
    "    # cat: 0, dog: 1\n",
    "    category = 1 if 'dog' in image_name else 0\n",
    "    labels.append(category)\n",
    "\n",
    "    \n",
    "# 猫的种类\n",
    "cat_types = ['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian',\n",
    "             'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx']\n",
    "# 处理扩展的训练数据\n",
    "for i in tqdm(range(len(image_names_train_extra))):\n",
    "    image_name = image_names_train_extra[i]\n",
    "    image_path = os.path.join(data_path_train_extra, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print('Read extra train image failed:', image_path)\n",
    "        continue\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    index = len(image_names_train) + i\n",
    "    trains.append(image[:, :, ::-1])\n",
    "    \n",
    "    # 获取动物的种类（dog or cat）\n",
    "    spt = image_names_train_extra[i].split('_')\n",
    "    spt.pop()\n",
    "    tp = '_'.join(spt)\n",
    "    category = 0 if tp in cat_types else 1\n",
    "    labels.append(category)\n",
    "    \n",
    "\n",
    "# 处理标准的测试数据\n",
    "for i in tqdm(range(len(image_names_test))):\n",
    "    image_name = image_names_test[i]\n",
    "    image_path = os.path.join(data_path_test, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print('Read test image failed:', image_path)\n",
    "        continue\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    tests.append(image[:, :, ::-1])\n",
    "    \n",
    "    \n",
    "trains = np.array(trains)\n",
    "labels = np.array(labels)\n",
    "tests = np.array(tests)\n",
    "\n",
    "print('Training data size: %d' % len(trains))\n",
    "print('Label size: %d' % len(labels))\n",
    "print('Testing data size: %d' % len(tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck features have been wrote to bottleneck_features.h5\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=input_shape)\n",
    "x = Lambda(xception.preprocess_input)(x)\n",
    "model = Xception(input_tensor=x, input_shape=input_shape, weights='imagenet', include_top=False, pooling='avg')\n",
    "bottleneck_features_train = model.predict(trains, batch_size=128)\n",
    "bottleneck_features_test = model.predict(tests, batch_size=128)\n",
    "\n",
    "with h5py.File(\"bottleneck_features.h5\", 'w') as h:\n",
    "    h.create_dataset('trains', data=bottleneck_features_train)\n",
    "    h.create_dataset('labels', data=labels)\n",
    "    h.create_dataset('tests', data=bottleneck_features_test)\n",
    "\n",
    "print('bottleneck features have been wrote to bottleneck_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('bottleneck_features.h5','r') as h:\n",
    "    X_train = np.array(h['trains'])\n",
    "    y_train = np.array(h['labels'])\n",
    "    X_test = np.array(h['tests'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.2, random_state=2018)\n",
    "\n",
    "x = Input(shape=(X_train.shape[1],))\n",
    "y = Dropout(0.3)(x)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "model = Model(x, y)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Model ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25907 samples, validate on 6477 samples\n",
      "Epoch 1/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0126 - acc: 0.9963 - val_loss: 0.0206 - val_acc: 0.9949\n",
      "Epoch 2/20\n",
      "25907/25907 [==============================] - 3s 114us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0208 - val_acc: 0.9948\n",
      "Epoch 3/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0117 - acc: 0.9964 - val_loss: 0.0208 - val_acc: 0.9948\n",
      "Epoch 4/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0122 - acc: 0.9961 - val_loss: 0.0204 - val_acc: 0.9954\n",
      "Epoch 5/20\n",
      "25907/25907 [==============================] - 3s 114us/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0204 - val_acc: 0.9954\n",
      "Epoch 6/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0205 - val_acc: 0.9957\n",
      "Epoch 7/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0111 - acc: 0.9966 - val_loss: 0.0204 - val_acc: 0.9951\n",
      "Epoch 8/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0203 - val_acc: 0.9949\n",
      "Epoch 9/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0106 - acc: 0.9967 - val_loss: 0.0204 - val_acc: 0.9955\n",
      "Epoch 10/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.0204 - val_acc: 0.9951\n",
      "Epoch 11/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0204 - val_acc: 0.9955\n",
      "Epoch 12/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0109 - acc: 0.9965 - val_loss: 0.0205 - val_acc: 0.9949\n",
      "Epoch 13/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0204 - val_acc: 0.9957\n",
      "Epoch 14/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0211 - val_acc: 0.9948\n",
      "Epoch 15/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0100 - acc: 0.9967 - val_loss: 0.0208 - val_acc: 0.9949\n",
      "Epoch 16/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0203 - val_acc: 0.9958\n",
      "Epoch 17/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0204 - val_acc: 0.9957\n",
      "Epoch 18/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0205 - val_acc: 0.9957\n",
      "Epoch 19/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0207 - val_acc: 0.9951\n",
      "Epoch 20/20\n",
      "25907/25907 [==============================] - 3s 113us/step - loss: 0.0096 - acc: 0.9971 - val_loss: 0.0204 - val_acc: 0.9954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b73b05a20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=20, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "for i in range(len(image_names_test)):\n",
    "    image_name = image_names_test[i]\n",
    "    index = int(str.split(image_name, '.')[0]) - 1\n",
    "    df.iat[index, 1] = y_pred[i]\n",
    "\n",
    "df.to_csv('predict.csv', index=None)\n",
    "print('The prediction result has been wrote to predict.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
