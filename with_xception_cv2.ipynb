{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications import Xception, xception\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Dense, Input, Lambda\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:00<00:00, 415.74it/s]\n",
      "100%|██████████| 12500/12500 [00:30<00:00, 415.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 25000\n",
      "Label size: 25000\n",
      "Testing data size: 12500\n"
     ]
    }
   ],
   "source": [
    "data_path_train = '../dogs-vs-cats-dataset/train'\n",
    "data_path_test = '../dogs-vs-cats-dataset/test'\n",
    "image_names_train = os.listdir(data_path_train)\n",
    "image_names_test = os.listdir(data_path_test)\n",
    "input_shape = (299, 299, 3)\n",
    "labels = []\n",
    "trains = []\n",
    "tests = []\n",
    "\n",
    "# 处理标准的训练数据\n",
    "for i in tqdm(range(len(image_names_train))):\n",
    "    image_name = image_names_train[i]\n",
    "    image_path = os.path.join(data_path_train, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print('Read train image failed:', image_path)\n",
    "        continue\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    trains.append(image[:, :, ::-1])\n",
    "    # cat: 0, dog: 1\n",
    "    category = 1 if 'dog' in image_name else 0\n",
    "    labels.append(category)\n",
    "\n",
    "\n",
    "# 处理标准的测试数据\n",
    "for i in tqdm(range(len(image_names_test))):\n",
    "    image_name = image_names_test[i]\n",
    "    image_path = os.path.join(data_path_test, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print('Read test image failed:', image_path)\n",
    "        continue\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    tests.append(image[:, :, ::-1])\n",
    "    \n",
    "    \n",
    "trains = np.array(trains)\n",
    "labels = np.array(labels)\n",
    "tests = np.array(tests)\n",
    "\n",
    "print('Training data size: %d' % len(trains))\n",
    "print('Label size: %d' % len(labels))\n",
    "print('Testing data size: %d' % len(tests))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=input_shape)\n",
    "x = Lambda(xception.preprocess_input)(x)\n",
    "model = Xception(input_tensor=x, input_shape=input_shape, weights='imagenet', include_top=False, pooling='avg')\n",
    "bottleneck_features_train = model.predict(trains, batch_size=128)\n",
    "bottleneck_features_test = model.predict(tests, batch_size=128)\n",
    "\n",
    "with h5py.File(\"bottleneck_features.h5\", 'w') as h:\n",
    "    h.create_dataset('trains', data=bottleneck_features_train)\n",
    "    h.create_dataset('labels', data=labels)\n",
    "    h.create_dataset('tests', data=bottleneck_features_test)\n",
    "    h.create_dataset('test_imgs', data=image_names_test)\n",
    "\n",
    "print('bottleneck features have been wrote to bottleneck_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('bottleneck_features.h5','r') as h:\n",
    "    X_train = np.array(h['trains'])\n",
    "    y_train = np.array(h['labels'])\n",
    "    X_test = np.array(h['tests'])\n",
    "    test_imgs = np.array(h['test_imgs'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.2, random_state=2018)\n",
    "\n",
    "x = Input(shape=(X_train.shape[1],))\n",
    "y = Dropout(0.2)(x)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "model = Model(x, y)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Model ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(mod, file_name):\n",
    "    y_pred = mod.predict(X_test, verbose=1)\n",
    "    y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "    for i in range(len(test_imgs)):\n",
    "        image_name = test_imgs[i]\n",
    "        index = int(str.split(image_name, '.')[0]) - 1\n",
    "        df.iat[index, 1] = y_pred[i]\n",
    "\n",
    "    df.to_csv(os.path.join('./predict-csv', file_name), index=None)\n",
    "    print('The prediction result has been wrote to: ', file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回调函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        predict_func(self.model, 'predict' + '_epoch' + str(epoch + 1) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练与优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 1s 54us/step - loss: 0.1346 - acc: 0.9815 - val_loss: 0.0476 - val_acc: 0.9906\n",
      "12500/12500 [==============================] - 0s 40us/step\n",
      "The prediction result has been wrote to:  predict_epoch1.csv\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0334 - acc: 0.9930 - val_loss: 0.0297 - val_acc: 0.9916\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch2.csv\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 1s 29us/step - loss: 0.0231 - acc: 0.9937 - val_loss: 0.0259 - val_acc: 0.9924\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch3.csv\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0202 - acc: 0.9944 - val_loss: 0.0247 - val_acc: 0.9922\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch4.csv\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0241 - val_acc: 0.9922\n",
      "12500/12500 [==============================] - 0s 29us/step\n",
      "The prediction result has been wrote to:  predict_epoch5.csv\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0168 - acc: 0.9950 - val_loss: 0.0236 - val_acc: 0.9920\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch6.csv\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0158 - acc: 0.9954 - val_loss: 0.0231 - val_acc: 0.9924\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch7.csv\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0156 - acc: 0.9950 - val_loss: 0.0229 - val_acc: 0.9924\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch8.csv\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 1s 31us/step - loss: 0.0143 - acc: 0.9956 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch9.csv\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 1s 30us/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "12500/12500 [==============================] - 0s 30us/step\n",
      "The prediction result has been wrote to:  predict_epoch10.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff6d591ca90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[LossCallback()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 82us/step\n",
      "The prediction result has been wrote to predict.csv\n"
     ]
    }
   ],
   "source": [
    "predict_func(model, 'predict.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
