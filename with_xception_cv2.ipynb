{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications import Xception, xception\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input, Lambda\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 107.35it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 179.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 30\n",
      "Training data size: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nb_train = 0\n",
    "nb_test = 0\n",
    "data_path_train = './dataset-mini-30-15/train'\n",
    "data_path_test = './dataset-mini-30-15/test'\n",
    "image_names_train = os.listdir(data_path_train)\n",
    "image_names_test = os.listdir(data_path_test)\n",
    "# 训练样本数量\n",
    "nb_train = len(image_names_train)\n",
    "# 测试样本数量\n",
    "nb_test = len(image_names_test)\n",
    "input_shape = (299, 299, 3)\n",
    "labels = np.zeros(nb_train)\n",
    "trains = np.zeros((nb_train,) + input_shape, dtype=np.uint8)\n",
    "tests = np.zeros((nb_test,) + input_shape, dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(nb_train)):\n",
    "    image_name = image_names_train[i]\n",
    "    image_path = data_path_train + '/' + image_name\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    trains[i] = image[:, :, ::-1]\n",
    "    # cat: 0, dog: 1\n",
    "    category = 1 if 'dog' in image_name else 0\n",
    "    labels[i] = category\n",
    "    \n",
    "for i in tqdm(range(nb_test)):\n",
    "    image_name = image_names_test[i]\n",
    "    image_path = data_path_test + '/' + image_name\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (input_shape[0], input_shape[1]))\n",
    "    tests[i] = image[:, :, ::-1]\n",
    "\n",
    "print('Training data size: %d' % nb_train)\n",
    "print('Training data size: %d' % nb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottleneck features have been wrote to bottleneck_features.h5\n"
     ]
    }
   ],
   "source": [
    "x = Input(shape=input_shape)\n",
    "x = Lambda(xception.preprocess_input)(x)\n",
    "model = Xception(input_tensor=x, input_shape=input_shape, weights='imagenet', include_top=False, pooling='avg')\n",
    "bottleneck_features_train = model.predict(trains, batch_size=128)\n",
    "bottleneck_features_test = model.predict(tests, batch_size=128)\n",
    "\n",
    "with h5py.File(\"bottleneck_features.h5\", 'w') as h:\n",
    "    h.create_dataset('trains', data=bottleneck_features_train)\n",
    "    h.create_dataset('labels', data=labels)\n",
    "    h.create_dataset('tests', data=bottleneck_features_test)\n",
    "\n",
    "print('bottleneck features have been wrote to bottleneck_features.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready!\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('bottleneck_features.h5','r') as h:\n",
    "    X_train = np.array(h['trains'])\n",
    "    y_train = np.array(h['labels'])\n",
    "    X_test = np.array(h['tests'])\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.2, random_state=2018)\n",
    "\n",
    "x = Input(shape=(X_train.shape[1],))\n",
    "y = Dropout(0.3)(x)\n",
    "y = Dense(1, activation='sigmoid')(y)\n",
    "model = Model(x, y)\n",
    "\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print('Model ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(24, 2048)\n",
      "(24,)\n",
      "(6, 2048)\n",
      "(6,)\n",
      "Train on 24 samples, validate on 6 samples\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 0.7605 - acc: 0.4167 - val_loss: 0.6040 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 0s 282us/step - loss: 0.6312 - acc: 0.7500 - val_loss: 0.5719 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 0s 379us/step - loss: 0.6240 - acc: 0.7500 - val_loss: 0.5348 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 0s 735us/step - loss: 0.5104 - acc: 0.9167 - val_loss: 0.5073 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 0s 392us/step - loss: 0.5048 - acc: 0.9583 - val_loss: 0.4788 - val_acc: 1.0000\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 0s 750us/step - loss: 0.4305 - acc: 1.0000 - val_loss: 0.4555 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 0s 343us/step - loss: 0.3934 - acc: 1.0000 - val_loss: 0.4355 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 0s 898us/step - loss: 0.3684 - acc: 1.0000 - val_loss: 0.4265 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 0s 410us/step - loss: 0.3088 - acc: 1.0000 - val_loss: 0.4182 - val_acc: 0.8333\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 0s 721us/step - loss: 0.3101 - acc: 1.0000 - val_loss: 0.4026 - val_acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12374bc50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=15, epochs=10, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 65us/step\n",
      "The prediction result has been wrote to pred.csv\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "for i in range(nb_test):\n",
    "    image_name = image_names_test[i]\n",
    "    index = int(str.split(image_name, '.')[0]) - 1\n",
    "    df.iat[index, 1] = y_pred[i]\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "print('The prediction result has been wrote to pred.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
